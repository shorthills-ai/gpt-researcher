2025-05-07 12:06:31,393 - backend.server.server_utils - ERROR - Error running task: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 126, in run_agent
    researcher = BasicReport(
                 ^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 33, in __init__
    self.gpt_researcher = GPTResearcher(
                          ^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 88, in __init__
    self.memory = Memory(
                  ^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/memory/embeddings.py", line 47, in __init__
    _embeddings = OpenAIEmbeddings(model=model, **embdding_kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/pydantic/main.py", line 214, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 338, in validate_environment
    self.client = openai.OpenAI(**client_params, **sync_specific).embeddings  # type: ignore[arg-type]
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_client.py", line 110, in __init__
    raise OpenAIError(
openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable

2025-05-07 12:13:26,149 - backend.server.server_utils - ERROR - Error running task: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 126, in run_agent
    researcher = BasicReport(
                 ^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 33, in __init__
    self.gpt_researcher = GPTResearcher(
                          ^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 88, in __init__
    self.memory = Memory(
                  ^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/memory/embeddings.py", line 47, in __init__
    _embeddings = OpenAIEmbeddings(model=model, **embdding_kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/pydantic/main.py", line 214, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 338, in validate_environment
    self.client = openai.OpenAI(**client_params, **sync_specific).embeddings  # type: ignore[arg-type]
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_client.py", line 110, in __init__
    raise OpenAIError(
openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable

2025-05-07 12:13:29,144 - backend.server.server_utils - ERROR - Error running task: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 126, in run_agent
    researcher = BasicReport(
                 ^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 33, in __init__
    self.gpt_researcher = GPTResearcher(
                          ^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 88, in __init__
    self.memory = Memory(
                  ^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/memory/embeddings.py", line 47, in __init__
    _embeddings = OpenAIEmbeddings(model=model, **embdding_kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/pydantic/main.py", line 214, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 338, in validate_environment
    self.client = openai.OpenAI(**client_params, **sync_specific).embeddings  # type: ignore[arg-type]
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_client.py", line 110, in __init__
    raise OpenAIError(
openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable

2025-05-07 12:13:49,355 - backend.server.server_utils - ERROR - Error running task: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 126, in run_agent
    researcher = BasicReport(
                 ^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 33, in __init__
    self.gpt_researcher = GPTResearcher(
                          ^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 88, in __init__
    self.memory = Memory(
                  ^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/memory/embeddings.py", line 47, in __init__
    _embeddings = OpenAIEmbeddings(model=model, **embdding_kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/pydantic/main.py", line 214, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 338, in validate_environment
    self.client = openai.OpenAI(**client_params, **sync_specific).embeddings  # type: ignore[arg-type]
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_client.py", line 110, in __init__
    raise OpenAIError(
openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable

2025-05-07 12:14:16,656 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:14:16,658 - openai._base_client - INFO - Retrying request to /chat/completions in 0.424979 seconds
2025-05-07 12:14:17,389 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:14:17,391 - openai._base_client - INFO - Retrying request to /chat/completions in 0.971135 seconds
2025-05-07 12:14:18,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:14:18,733 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1636, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1683, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1636, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1683, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 12:14:38,456 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:14:38,457 - openai._base_client - INFO - Retrying request to /chat/completions in 0.440284 seconds
2025-05-07 12:14:39,211 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:14:39,211 - openai._base_client - INFO - Retrying request to /chat/completions in 0.962651 seconds
2025-05-07 12:14:40,468 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:14:40,473 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1636, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1683, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1636, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1683, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 12:15:09,259 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:15:09,261 - openai._base_client - INFO - Retrying request to /chat/completions in 0.456562 seconds
2025-05-07 12:15:10,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:15:10,056 - openai._base_client - INFO - Retrying request to /chat/completions in 0.909048 seconds
2025-05-07 12:15:11,295 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:15:11,300 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1636, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1683, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1636, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1683, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 12:16:17,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:16:17,401 - openai._base_client - INFO - Retrying request to /chat/completions in 0.477594 seconds
2025-05-07 12:16:18,165 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:16:18,166 - openai._base_client - INFO - Retrying request to /chat/completions in 0.856484 seconds
2025-05-07 12:16:19,324 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:16:19,346 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1636, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1683, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1636, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1683, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 12:18:38,277 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:18:38,279 - openai._base_client - INFO - Retrying request to /chat/completions in 0.380526 seconds
2025-05-07 12:18:38,989 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:18:38,991 - openai._base_client - INFO - Retrying request to /chat/completions in 0.954813 seconds
2025-05-07 12:18:40,245 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:18:40,260 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1636, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1683, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1636, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1683, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 12:19:51,212 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:19:51,214 - openai._base_client - INFO - Retrying request to /chat/completions in 0.456308 seconds
2025-05-07 12:19:51,978 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:19:51,979 - openai._base_client - INFO - Retrying request to /chat/completions in 0.839013 seconds
2025-05-07 12:19:53,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-05-07 12:19:53,128 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1636, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1683, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1636, in _request
    return await self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1683, in _retry_request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 12:22:59,241 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-05-07 12:22:59,263 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: qrstefgh****************************efgh. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 12:24:54,377 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-05-07 12:24:54,381 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: qrstefgh****************************efgh. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 14:03:29,631 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-05-07 14:03:29,686 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 5fc5479a********************e8fb. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 14:04:36,408 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-05-07 14:04:36,424 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 5fc5479a********************e8fb. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 14:05:22,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-05-07 14:05:22,941 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 5fc5479a********************e8fb. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 14:43:37,750 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-05-07 14:43:37,829 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 5fc5479a********************e8fb. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 14:53:47,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-05-07 14:53:47,881 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 5fc5479a********************e8fb. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 14:57:09,331 - backend.server.server_utils - ERROR - Error running task: 'AZURE_OPENAI_API_VERSION'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 126, in run_agent
    researcher = BasicReport(
                 ^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 33, in __init__
    self.gpt_researcher = GPTResearcher(
                          ^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 88, in __init__
    self.memory = Memory(
                  ^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/memory/embeddings.py", line 55, in __init__
    openai_api_version=os.environ["AZURE_OPENAI_API_VERSION"],
                       ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen os>", line 679, in __getitem__
KeyError: 'AZURE_OPENAI_API_VERSION'

2025-05-07 14:57:43,256 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 78, in create_chat_completion
    provider = get_llm(llm_provider, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 20, in get_llm
    return GenericLLMProvider.from_provider(llm_provider, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 103, in from_provider
    llm = AzureChatOpenAI(**kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/load/serializable.py", line 125, in __init__
    super().__init__(*args, **kwargs)
  File "/opt/homebrew/lib/python3.11/site-packages/pydantic/main.py", line 214, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for AzureChatOpenAI
  Value error, Must provide either the `api_version` argument or the `OPENAI_API_VERSION` environment variable [type=value_error, input_value={'azure_deployment': 'gpt...000, 'model_kwargs': {}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/value_error

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 14:58:33,467 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/Deployment/openai/deployments/gpt-4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 404 Resource Not Found"
2025-05-07 14:58:33,531 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 14:59:16,233 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/Deployment/openai/deployments/gpt-4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 404 Resource Not Found"
2025-05-07 14:59:16,245 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 15:00:15,886 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:00:15,902 - backend.server.server_utils - ERROR - Error running task: expected string or bytes-like object, got 'NoneType'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 33, in choose_agent
    response = await create_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/utils/llm.py", line 82, in create_chat_completion
    response = await provider.get_chat_response(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/llm_provider/generic/base.py", line 220, in get_chat_response
    output = await self.llm.ainvoke(messages)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 305, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 870, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 830, in agenerate
    raise exceptions[0]
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py", line 998, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py", line 825, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1927, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1856, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1550, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1651, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 47, in run
    await self.gpt_researcher.conduct_research()
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 138, in conduct_research
    self.agent, self.role = await choose_agent(
                            ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 49, in choose_agent
    return await handle_json_error(response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 61, in handle_json_error
    json_string = extract_json_with_regex(response)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/agent_creator.py", line 77, in extract_json_with_regex
    json_match = re.search(r"{.*?}", response, re.DOTALL)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 176, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'NoneType'

2025-05-07 15:02:40,152 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:02:46,172 - research - INFO - Starting research for query: hi
2025-05-07 15:02:46,179 - research - INFO - Using web search
2025-05-07 15:02:46,179 - research - INFO - Starting web search for query: hi
2025-05-07 15:02:46,179 - research - INFO - Planning research for query: hi
2025-05-07 15:02:46,923 - research - INFO - Initial search results obtained: 0 results
2025-05-07 15:02:48,725 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:02:48,728 - research - INFO - Research outline planned: ['current trends in greeting etiquette 2025', 'psychological impact of greetings on social interactions', 'cultural significance of saying hi in different countries']
2025-05-07 15:02:48,728 - research - INFO - Generated sub-queries: ['current trends in greeting etiquette 2025', 'psychological impact of greetings on social interactions', 'cultural significance of saying hi in different countries']
2025-05-07 15:02:49,485 - research - INFO - Scraped data size: 0
2025-05-07 15:02:53,419 - research - INFO - Scraped data size: 0
2025-05-07 15:02:53,435 - research - INFO - Scraped data size: 0
2025-05-07 15:02:53,447 - research - INFO - Scraped data size: 0
2025-05-07 15:02:53,451 - research - INFO - Content found for sub-query: 0 chars
2025-05-07 15:02:53,454 - research - INFO - Content found for sub-query: 0 chars
2025-05-07 15:02:53,455 - research - INFO - Content found for sub-query: 0 chars
2025-05-07 15:02:53,457 - research - INFO - Content found for sub-query: 0 chars
2025-05-07 15:02:53,459 - research - INFO - Gathered context from 4 sub-queries
2025-05-07 15:02:53,460 - research - INFO - Research completed. Context size: 2
2025-05-07 15:02:54,273 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:02:55,691 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:02:55,737 - backend.server.server_utils - ERROR - Error running task: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 84, in start_streaming
    self.chat_agent = ChatAgentWithMemory(report, config_path, headers)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 27, in __init__
    self.graph = self.create_agent()
                 ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 52, in create_agent
    self.vector_store.add_texts(documents)
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/base.py", line 111, in add_texts
    return self.add_documents(docs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/in_memory.py", line 175, in add_documents
    vectors = self.embedding.embed_documents(texts)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}

2025-05-07 15:04:47,180 - backend.server.server_utils - ERROR - Error running task: 'AZURE_OPENAI_API_VERSION'
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 126, in run_agent
    researcher = BasicReport(
                 ^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 33, in __init__
    self.gpt_researcher = GPTResearcher(
                          ^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 88, in __init__
    self.memory = Memory(
                  ^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/memory/embeddings.py", line 55, in __init__
    openai_api_version=os.environ["AZURE_OPENAI_API_VERSION"],
                       ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen os>", line 679, in __getitem__
KeyError: 'AZURE_OPENAI_API_VERSION'

2025-05-07 15:05:04,428 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:05:04,653 - research - INFO - Starting research for query: ipl
2025-05-07 15:05:04,659 - research - INFO - Using web search
2025-05-07 15:05:04,659 - research - INFO - Starting web search for query: ipl
2025-05-07 15:05:04,659 - research - INFO - Planning research for query: ipl
2025-05-07 15:05:06,948 - research - INFO - Initial search results obtained: 10 results
2025-05-07 15:05:08,490 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:05:08,497 - research - INFO - Research outline planned: ['IPL 2025 match reports and highlights', 'Mumbai Indians performance IPL 2025', 'Gujarat Titans vs Mumbai Indians IPL 2025 result']
2025-05-07 15:05:08,497 - research - INFO - Generated sub-queries: ['IPL 2025 match reports and highlights', 'Mumbai Indians performance IPL 2025', 'Gujarat Titans vs Mumbai Indians IPL 2025 result']
2025-05-07 15:05:10,581 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,582 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,583 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,585 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,588 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,637 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,637 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,638 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,639 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,640 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,647 - gpt_researcher.scraper.scraper - INFO - 
Title: Access Denied
2025-05-07 15:05:10,647 - gpt_researcher.scraper.scraper - INFO - Content length: 244 characters
2025-05-07 15:05:10,647 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-07 15:05:10,647 - gpt_researcher.scraper.scraper - INFO - URL: https://www.espncricinfo.com/series/ipl-2025-1449924/videos
2025-05-07 15:05:10,647 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:10,680 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025 Match Reports | Results & Analysis | IPLT20
2025-05-07 15:05:10,681 - gpt_researcher.scraper.scraper - INFO - Content length: 2628 characters
2025-05-07 15:05:10,681 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-07 15:05:10,681 - gpt_researcher.scraper.scraper - INFO - URL: https://www.iplt20.com/news/match-reports
2025-05-07 15:05:10,681 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:10,712 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025 Match Highlights | Watch All Match Videos | IPLT20
2025-05-07 15:05:10,713 - gpt_researcher.scraper.scraper - INFO - Content length: 4251 characters
2025-05-07 15:05:10,713 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-07 15:05:10,713 - gpt_researcher.scraper.scraper - INFO - URL: https://www.iplt20.com/videos/highlights
2025-05-07 15:05:10,713 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:10,806 - gpt_researcher.scraper.scraper - INFO - 
Title: MI vs GT IPL 2025 Highlights: Gujarat Titans beat Mumbai Indians by 3 wickets (DLS) in rain-affected match  Firstpost
2025-05-07 15:05:10,806 - gpt_researcher.scraper.scraper - INFO - Content length: 18619 characters
2025-05-07 15:05:10,806 - gpt_researcher.scraper.scraper - INFO - Number of images: 1
2025-05-07 15:05:10,806 - gpt_researcher.scraper.scraper - INFO - URL: https://www.firstpost.com/firstcricket/mi-vs-gt-ipl-2025-live-score-high-flying-mumbai-indians-eye-revenge-against-gujarat-titans-at-wankhede-liveblog-13885955.html
2025-05-07 15:05:10,806 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:10,820 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025: Mumbai Indians achieve historic first in 13-years against Rajasthan Royals | Cricket News - The Times of India
2025-05-07 15:05:10,820 - gpt_researcher.scraper.scraper - INFO - Content length: 14329 characters
2025-05-07 15:05:10,820 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-07 15:05:10,820 - gpt_researcher.scraper.scraper - INFO - URL: https://timesofindia.indiatimes.com/sports/cricket/ipl/top-stories/ipl-2025-mumbai-indians-achieve-historic-first-in-13-years-against-rajasthan-royals/articleshow/120808548.cms
2025-05-07 15:05:10,820 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:10,851 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025 Points Table: Gujarat Titans Topple Royal Challengers Bengaluru To Claim Top Spot, Mumbai Indians Slip Down To... | Cricket News
2025-05-07 15:05:10,851 - gpt_researcher.scraper.scraper - INFO - Content length: 5120 characters
2025-05-07 15:05:10,851 - gpt_researcher.scraper.scraper - INFO - Number of images: 7
2025-05-07 15:05:10,851 - gpt_researcher.scraper.scraper - INFO - URL: https://sports.ndtv.com/ipl-2025/ipl-2025-points-table-gujarat-titans-topple-royal-challengers-bengaluru-to-claim-top-spot-mumbai-indians-slip-down-to-8349819
2025-05-07 15:05:10,851 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:10,913 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,913 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,913 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,914 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:10,959 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL T20 | Indian Premier League Official Website
2025-05-07 15:05:10,959 - gpt_researcher.scraper.scraper - INFO - Content length: 1504 characters
2025-05-07 15:05:10,959 - gpt_researcher.scraper.scraper - INFO - Number of images: 7
2025-05-07 15:05:10,959 - gpt_researcher.scraper.scraper - INFO - URL: https://www.iplt20.com/
2025-05-07 15:05:10,959 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:11,058 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:11,058 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:11,058 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:05:11,058 - gpt_researcher.scraper.scraper - INFO - 
Title: 
	MI vs GT highlights,IPL2025: Gujarat Titans beats Mumbai Indians in last-over thriller - Sportstar

2025-05-07 15:05:11,058 - gpt_researcher.scraper.scraper - INFO - Content length: 21513 characters
2025-05-07 15:05:11,058 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-07 15:05:11,059 - gpt_researcher.scraper.scraper - INFO - URL: https://sportstar.thehindu.com/cricket/ipl/ipl-news/mi-vs-gt-live-score-mumbai-indians-gujarat-titans-ipl-2025-match-streaming-info-highlights/article69544750.ece
2025-05-07 15:05:11,059 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:11,059 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025 | Live Cricket Score, Schedule, Latest News, Stats &amp; Videos | Cricbuzz.com
2025-05-07 15:05:11,059 - gpt_researcher.scraper.scraper - INFO - Content length: 10999 characters
2025-05-07 15:05:11,059 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-07 15:05:11,059 - gpt_researcher.scraper.scraper - INFO - URL: https://m.cricbuzz.com/
2025-05-07 15:05:11,059 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:11,059 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025 Videos | Highlights, Magic Moments & More | IPLT20
2025-05-07 15:05:11,059 - gpt_researcher.scraper.scraper - INFO - Content length: 7114 characters
2025-05-07 15:05:11,059 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-07 15:05:11,059 - gpt_researcher.scraper.scraper - INFO - URL: https://www.iplt20.com/videos?mid=b9ad3f1be588491ea99c7e592965fe7c
2025-05-07 15:05:11,059 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:11,098 - gpt_researcher.scraper.scraper - INFO - 
Title: Access Denied
2025-05-07 15:05:11,098 - gpt_researcher.scraper.scraper - INFO - Content length: 302 characters
2025-05-07 15:05:11,098 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-07 15:05:11,098 - gpt_researcher.scraper.scraper - INFO - URL: https://www.espncricinfo.com/series/ipl-2025-1449924/mumbai-indians-vs-gujarat-titans-56th-match-1473493/match-report
2025-05-07 15:05:11,098 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:11,157 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025 Playoff qualification: How can Mumbai Indians qualify for top-4 finish? Scenario, points table cut-off, match schedule | Ipl News - The Indian Express
2025-05-07 15:05:11,158 - gpt_researcher.scraper.scraper - INFO - Content length: 7639 characters
2025-05-07 15:05:11,158 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-07 15:05:11,158 - gpt_researcher.scraper.scraper - INFO - URL: https://indianexpress.com/article/sports/ipl/ipl-2025-playoff-qualification-mumbai-indians-point-cutoff-schedule-9985204/
2025-05-07 15:05:11,158 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:11,249 - gpt_researcher.scraper.scraper - INFO - 
Title: Mumbai Indians vs Gujarat Titans, IPL 2025: Hardik Pandya's Last Over Gamble Backfires As GT Edge Out MI To Claim Top Spot | Cricket News
2025-05-07 15:05:11,249 - gpt_researcher.scraper.scraper - INFO - Content length: 15509 characters
2025-05-07 15:05:11,249 - gpt_researcher.scraper.scraper - INFO - Number of images: 9
2025-05-07 15:05:11,249 - gpt_researcher.scraper.scraper - INFO - URL: https://sports.ndtv.com/ipl-2025/mumbai-indians-vs-gujarat-titans-live-score-mi-vs-gt-live-updates-ipl-2025-rohit-sharma-shubman-gill-hardik-pandya-8343772
2025-05-07 15:05:11,249 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:11,323 - gpt_researcher.scraper.scraper - INFO - 
Title: Updated IPL 2025 Points Table After Gujarat Titans Defeat Mumbai Indians In Last Ball Thriller | Republic World
2025-05-07 15:05:11,323 - gpt_researcher.scraper.scraper - INFO - Content length: 3413 characters
2025-05-07 15:05:11,323 - gpt_researcher.scraper.scraper - INFO - Number of images: 6
2025-05-07 15:05:11,323 - gpt_researcher.scraper.scraper - INFO - URL: https://www.republicworld.com/cricket/updated-ipl-2025-points-table-after-gujarat-titans-defeat-mumbai-indians-in-last-ball-thriller
2025-05-07 15:05:11,323 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:11,338 - research - INFO - Scraped data size: 5
2025-05-07 15:05:11,562 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025, MI Vs GT Highlights: Titans Steal Unbelievable 3-Wicket Win In Late-Night Thriller - News18
2025-05-07 15:05:11,562 - gpt_researcher.scraper.scraper - INFO - Content length: 21951 characters
2025-05-07 15:05:11,562 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-07 15:05:11,562 - gpt_researcher.scraper.scraper - INFO - URL: https://www.news18.com/cricket/ipl-2025-mi-vs-gt-live-score-mumbai-indians-vs-gujarat-titans-today-ipl-match-toss-update-latest-scorecard-liveblog-9325899.html
2025-05-07 15:05:11,562 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:11,589 - research - INFO - Scraped data size: 4
2025-05-07 15:05:11,705 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025: Gujarat Titans beat Mumbai Indians - and rain - in extraordinary finish  - BBC Sport
2025-05-07 15:05:11,705 - gpt_researcher.scraper.scraper - INFO - Content length: 5775 characters
2025-05-07 15:05:11,705 - gpt_researcher.scraper.scraper - INFO - Number of images: 2
2025-05-07 15:05:11,705 - gpt_researcher.scraper.scraper - INFO - URL: https://www.bbc.co.uk/sport/cricket/articles/c98g8y1nl96o
2025-05-07 15:05:11,705 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:11,725 - research - INFO - Scraped data size: 3
2025-05-07 15:05:12,087 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025 : Match Summary And Highlights Recap & Playoffs
2025-05-07 15:05:12,087 - gpt_researcher.scraper.scraper - INFO - Content length: 8981 characters
2025-05-07 15:05:12,087 - gpt_researcher.scraper.scraper - INFO - Number of images: 9
2025-05-07 15:05:12,087 - gpt_researcher.scraper.scraper - INFO - URL: https://sportsdanka.com/cricket/ipl-2025-match-1-to-23-summary-highlights/
2025-05-07 15:05:12,087 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:05:12,109 - research - INFO - Scraped data size: 5
2025-05-07 15:05:12,528 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:05:12,530 - research - ERROR - Error processing sub-query Gujarat Titans vs Mumbai Indians IPL 2025 result: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:05:12,641 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:05:12,642 - research - ERROR - Error processing sub-query Mumbai Indians performance IPL 2025: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:05:12,648 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:05:12,650 - research - ERROR - Error processing sub-query ipl: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:05:13,119 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:05:13,120 - research - ERROR - Error processing sub-query IPL 2025 match reports and highlights: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:05:13,123 - research - INFO - Gathered context from 4 sub-queries
2025-05-07 15:05:13,125 - research - INFO - Research completed. Context size: 2
2025-05-07 15:05:14,282 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:05:41,911 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:05:42,393 - backend.server.server_utils - ERROR - Error running task: Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 48, in run
    report = await self.gpt_researcher.write_report()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 209, in write_report
    report = await self.report_generator.write_report(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/writer.py", line 81, in write_report
    await stream_output(
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/utils.py", line 29, in stream_output
    await websocket.send_json(
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 48, in send_json
    await self.websocket.send_json(data)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 175, in send_json
    await self.send({"type": "websocket.send", "text": text})
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 85, in send
    await self._send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/_exception_handler.py", line 39, in sender
    await send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py", line 359, in asgi_send
    raise RuntimeError(msg % message_type)
RuntimeError: Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.

2025-05-07 15:05:42,394 - asyncio - ERROR - Task exception was never retrieved
future: <Task finished name='Task-10' coro=<handle_websocket_communication.<locals>.run_long_running_task.<locals>.safe_run() done, defined at /Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py:253> exception=RuntimeError("Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.")>
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 48, in run
    report = await self.gpt_researcher.write_report()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 209, in write_report
    report = await self.report_generator.write_report(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/writer.py", line 81, in write_report
    await stream_output(
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/utils.py", line 29, in stream_output
    await websocket.send_json(
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 48, in send_json
    await self.websocket.send_json(data)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 175, in send_json
    await self.send({"type": "websocket.send", "text": text})
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 85, in send
    await self._send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/_exception_handler.py", line 39, in sender
    await send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py", line 359, in asgi_send
    raise RuntimeError(msg % message_type)
RuntimeError: Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 261, in safe_run
    await websocket.send_json(
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 175, in send_json
    await self.send({"type": "websocket.send", "text": text})
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 85, in send
    await self._send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/_exception_handler.py", line 39, in sender
    await send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py", line 359, in asgi_send
    raise RuntimeError(msg % message_type)
RuntimeError: Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.
2025-05-07 15:05:54,732 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:05:54,739 - research - INFO - Starting research for query: what is my grade
2025-05-07 15:05:54,747 - research - INFO - Using local search
2025-05-07 15:05:55,588 - research - INFO - Loaded 1 documents
2025-05-07 15:05:55,588 - research - INFO - Starting web search for query: what is my grade
2025-05-07 15:05:55,588 - research - INFO - Planning research for query: what is my grade
2025-05-07 15:05:57,926 - research - INFO - Initial search results obtained: 10 results
2025-05-07 15:05:59,329 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:05:59,335 - research - INFO - Research outline planned: ['how to calculate my final grade using online tools', 'best grade calculator for determining final course grade', 'calculate needed final exam score to achieve desired grade']
2025-05-07 15:05:59,335 - research - INFO - Generated sub-queries: ['how to calculate my final grade using online tools', 'best grade calculator for determining final course grade', 'calculate needed final exam score to achieve desired grade']
2025-05-07 15:05:59,980 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:05:59,981 - research - ERROR - Error processing sub-query how to calculate my final grade using online tools: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:06:00,012 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:06:00,013 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:06:00,014 - research - ERROR - Error processing sub-query calculate needed final exam score to achieve desired grade: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:06:00,016 - research - ERROR - Error processing sub-query what is my grade: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:06:00,021 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:06:00,022 - research - ERROR - Error processing sub-query best grade calculator for determining final course grade: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:06:00,023 - research - INFO - Gathered context from 4 sub-queries
2025-05-07 15:06:00,025 - research - INFO - Research completed. Context size: 2
2025-05-07 15:06:00,932 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:06:15,512 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:06:15,518 - backend.server.server_utils - ERROR - Error running task: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 84, in start_streaming
    self.chat_agent = ChatAgentWithMemory(report, config_path, headers)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 27, in __init__
    self.graph = self.create_agent()
                 ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 52, in create_agent
    self.vector_store.add_texts(documents)
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/base.py", line 111, in add_texts
    return self.add_documents(docs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/in_memory.py", line 175, in add_documents
    vectors = self.embedding.embed_documents(texts)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}

2025-05-07 15:06:38,466 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:06:38,470 - research - INFO - Starting research for query: do you have access to my documents
2025-05-07 15:06:38,475 - research - INFO - Using local search
2025-05-07 15:06:38,485 - research - INFO - Loaded 1 documents
2025-05-07 15:06:38,485 - research - INFO - Starting web search for query: do you have access to my documents
2025-05-07 15:06:38,485 - research - INFO - Planning research for query: do you have access to my documents
2025-05-07 15:06:40,894 - research - INFO - Initial search results obtained: 10 results
2025-05-07 15:06:42,282 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:06:42,290 - research - INFO - Research outline planned: ['how to manage access to my documents in OneDrive', 'troubleshooting access issues to My Documents folder in Windows 11', 'how to access documents stored in the cloud using Microsoft 365']
2025-05-07 15:06:42,290 - research - INFO - Generated sub-queries: ['how to manage access to my documents in OneDrive', 'troubleshooting access issues to My Documents folder in Windows 11', 'how to access documents stored in the cloud using Microsoft 365']
2025-05-07 15:06:42,921 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:06:42,922 - research - ERROR - Error processing sub-query how to manage access to my documents in OneDrive: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:06:42,957 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:06:42,959 - research - ERROR - Error processing sub-query how to access documents stored in the cloud using Microsoft 365: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:06:42,978 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:06:42,979 - research - ERROR - Error processing sub-query do you have access to my documents: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:06:43,014 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:06:43,015 - research - ERROR - Error processing sub-query troubleshooting access issues to My Documents folder in Windows 11: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:06:43,017 - research - INFO - Gathered context from 4 sub-queries
2025-05-07 15:06:43,027 - research - INFO - Research completed. Context size: 2
2025-05-07 15:06:43,829 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:06:51,998 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:06:52,332 - backend.server.server_utils - ERROR - Error running task: Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 48, in run
    report = await self.gpt_researcher.write_report()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 209, in write_report
    report = await self.report_generator.write_report(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/writer.py", line 81, in write_report
    await stream_output(
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/utils.py", line 29, in stream_output
    await websocket.send_json(
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 48, in send_json
    await self.websocket.send_json(data)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 175, in send_json
    await self.send({"type": "websocket.send", "text": text})
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 85, in send
    await self._send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/_exception_handler.py", line 39, in sender
    await send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py", line 359, in asgi_send
    raise RuntimeError(msg % message_type)
RuntimeError: Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.

2025-05-07 15:06:52,333 - asyncio - ERROR - Task exception was never retrieved
future: <Task finished name='Task-2067' coro=<handle_websocket_communication.<locals>.run_long_running_task.<locals>.safe_run() done, defined at /Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py:253> exception=RuntimeError("Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.")>
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 48, in run
    report = await self.gpt_researcher.write_report()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 209, in write_report
    report = await self.report_generator.write_report(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/writer.py", line 81, in write_report
    await stream_output(
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/utils.py", line 29, in stream_output
    await websocket.send_json(
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 48, in send_json
    await self.websocket.send_json(data)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 175, in send_json
    await self.send({"type": "websocket.send", "text": text})
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 85, in send
    await self._send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/_exception_handler.py", line 39, in sender
    await send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py", line 359, in asgi_send
    raise RuntimeError(msg % message_type)
RuntimeError: Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 261, in safe_run
    await websocket.send_json(
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 175, in send_json
    await self.send({"type": "websocket.send", "text": text})
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 85, in send
    await self._send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/_exception_handler.py", line 39, in sender
    await send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py", line 359, in asgi_send
    raise RuntimeError(msg % message_type)
RuntimeError: Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.
2025-05-07 15:10:38,557 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:10:38,563 - research - INFO - Starting research for query: what is the ipl
2025-05-07 15:10:38,578 - research - INFO - Starting web search for query: what is the ipl
2025-05-07 15:10:38,578 - research - INFO - Planning research for query: what is the ipl
2025-05-07 15:10:40,908 - research - INFO - Initial search results obtained: 10 results
2025-05-07 15:10:42,131 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:10:42,137 - research - INFO - Research outline planned: ['Indian Premier League 2025 overview', 'IPL cricket league latest news May 2025', 'Indian Premier League history and format']
2025-05-07 15:10:42,137 - research - INFO - Generated sub-queries: ['Indian Premier League 2025 overview', 'IPL cricket league latest news May 2025', 'Indian Premier League history and format']
2025-05-07 15:10:42,770 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:10:42,771 - research - ERROR - Error processing sub-query Indian Premier League 2025 overview: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:10:42,808 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:10:42,809 - research - ERROR - Error processing sub-query IPL cricket league latest news May 2025: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:10:42,819 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:10:42,820 - research - ERROR - Error processing sub-query Indian Premier League history and format: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:10:42,825 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:10:42,826 - research - ERROR - Error processing sub-query what is the ipl: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:10:42,827 - research - INFO - Gathered context from 4 sub-queries
2025-05-07 15:10:42,828 - research - INFO - Starting web search for query: what is the ipl
2025-05-07 15:10:42,828 - research - INFO - Planning research for query: what is the ipl
2025-05-07 15:10:45,887 - research - INFO - Initial search results obtained: 10 results
2025-05-07 15:10:47,434 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:10:47,441 - research - INFO - Research outline planned: ['Indian Premier League IPL 2025 overview', 'IPL cricket league history and format', 'IPL 2025 teams and player auction details']
2025-05-07 15:10:47,441 - research - INFO - Generated sub-queries: ['Indian Premier League IPL 2025 overview', 'IPL cricket league history and format', 'IPL 2025 teams and player auction details']
2025-05-07 15:10:49,762 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,764 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,765 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,766 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,768 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,858 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,859 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,860 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,862 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,864 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,939 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,939 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,940 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,942 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,943 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:49,949 - gpt_researcher.scraper.scraper - INFO - 
Title: Access Denied
2025-05-07 15:10:49,949 - gpt_researcher.scraper.scraper - INFO - Content length: 246 characters
2025-05-07 15:10:49,950 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-07 15:10:49,950 - gpt_researcher.scraper.scraper - INFO - URL: https://www.espncricinfo.com/auction/ipl-2025-auction-1460972
2025-05-07 15:10:49,950 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,079 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:50,083 - gpt_researcher.scraper.scraper - INFO - 
Title:    RealSelf - Access has been denied  
2025-05-07 15:10:50,084 - gpt_researcher.scraper.scraper - INFO - Content length: 463 characters
2025-05-07 15:10:50,084 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-07 15:10:50,084 - gpt_researcher.scraper.scraper - INFO - URL: https://www.realself.com/news/things-to-know-about-ipl
2025-05-07 15:10:50,084 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,084 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:50,129 - gpt_researcher.scraper.scraper - INFO - 
Title: Indian Premier League 2025 (IPL) matches, scorecards, preview, points table, news, videos and statistics | Cricbuzz.com
2025-05-07 15:10:50,130 - gpt_researcher.scraper.scraper - INFO - Content length: 10717 characters
2025-05-07 15:10:50,130 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-07 15:10:50,131 - gpt_researcher.scraper.scraper - INFO - URL: https://www.cricbuzz.com/cricket-series/9237/indian-premier-league-2025-ipl
2025-05-07 15:10:50,131 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,131 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:50,149 - gpt_researcher.scraper.scraper - INFO - 
Title:    RealSelf - Access has been denied  
2025-05-07 15:10:50,149 - gpt_researcher.scraper.scraper - INFO - Content length: 463 characters
2025-05-07 15:10:50,149 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-07 15:10:50,149 - gpt_researcher.scraper.scraper - INFO - URL: https://www.realself.com/nonsurgical/ipl
2025-05-07 15:10:50,149 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,150 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-07 15:10:50,160 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL Auction 2025 Full Players List, Prices, Sold and Unsold Players (by Team) - India Cricket Schedule
2025-05-07 15:10:50,160 - gpt_researcher.scraper.scraper - INFO - Content length: 7694 characters
2025-05-07 15:10:50,160 - gpt_researcher.scraper.scraper - INFO - Number of images: 1
2025-05-07 15:10:50,160 - gpt_researcher.scraper.scraper - INFO - URL: https://india.cricketschedule.com/ipl-auction-players-list-prices-teams/
2025-05-07 15:10:50,160 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,193 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025 Auction | Players Bought, Top Bids & Team Spending | IPLT20
2025-05-07 15:10:50,193 - gpt_researcher.scraper.scraper - INFO - Content length: 28722 characters
2025-05-07 15:10:50,193 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-07 15:10:50,193 - gpt_researcher.scraper.scraper - INFO - URL: https://www.iplt20.com/auction
2025-05-07 15:10:50,193 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,203 - gpt_researcher.scraper.scraper - INFO - 
Title: Intense Pulsed Light Therapy (IPL Treatment)
2025-05-07 15:10:50,203 - gpt_researcher.scraper.scraper - INFO - Content length: 11540 characters
2025-05-07 15:10:50,203 - gpt_researcher.scraper.scraper - INFO - Number of images: 5
2025-05-07 15:10:50,203 - gpt_researcher.scraper.scraper - INFO - URL: https://www.webmd.com/beauty/intense-pulsed-light-treatment-overview
2025-05-07 15:10:50,203 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,372 - gpt_researcher.scraper.scraper - INFO - 
Title: Indian Premier League (IPL) | Score, 2023, 2024, & Auction | Britannica
2025-05-07 15:10:50,372 - gpt_researcher.scraper.scraper - INFO - Content length: 10613 characters
2025-05-07 15:10:50,372 - gpt_researcher.scraper.scraper - INFO - Number of images: 1
2025-05-07 15:10:50,373 - gpt_researcher.scraper.scraper - INFO - URL: https://www.britannica.com/topic/Indian-Premier-League
2025-05-07 15:10:50,373 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,582 - gpt_researcher.scraper.scraper - INFO - 
Title: Indian Premier League - Wikipedia
2025-05-07 15:10:50,582 - gpt_researcher.scraper.scraper - INFO - Content length: 95378 characters
2025-05-07 15:10:50,583 - gpt_researcher.scraper.scraper - INFO - Number of images: 2
2025-05-07 15:10:50,583 - gpt_researcher.scraper.scraper - INFO - URL: https://en.wikipedia.org/wiki/Indian_Premier_League
2025-05-07 15:10:50,583 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,604 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL Auction 2025 - List of Players Team-wise with Base and Sold Price 
2025-05-07 15:10:50,604 - gpt_researcher.scraper.scraper - INFO - Content length: 32751 characters
2025-05-07 15:10:50,605 - gpt_researcher.scraper.scraper - INFO - Number of images: 6
2025-05-07 15:10:50,605 - gpt_researcher.scraper.scraper - INFO - URL: https://www.jagranjosh.com/general-knowledge/ipl-2025-mega-auction-list-of-players-team-wise-with-base-and-sold-price-1732451915-1
2025-05-07 15:10:50,605 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,610 - gpt_researcher.scraper.scraper - INFO - 
Title: Indian Premier League (IPL) 2025 Overview Fact-File
2025-05-07 15:10:50,610 - gpt_researcher.scraper.scraper - INFO - Content length: 10447 characters
2025-05-07 15:10:50,610 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-07 15:10:50,610 - gpt_researcher.scraper.scraper - INFO - URL: https://www.fact-file.com/indian-premier-league-ipl-2025-overview/
2025-05-07 15:10:50,610 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,646 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL Treatment: Cost, Procedure, and More
2025-05-07 15:10:50,647 - gpt_researcher.scraper.scraper - INFO - Content length: 12842 characters
2025-05-07 15:10:50,647 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-07 15:10:50,647 - gpt_researcher.scraper.scraper - INFO - URL: https://www.healthline.com/health/ipl-treatment
2025-05-07 15:10:50,647 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,670 - research - INFO - Scraped data size: 5
2025-05-07 15:10:50,760 - gpt_researcher.scraper.scraper - INFO - 
Title: Indian Premier League (IPL)  History, Teams, Format & Records - Careerindia 
2025-05-07 15:10:50,760 - gpt_researcher.scraper.scraper - INFO - Content length: 8374 characters
2025-05-07 15:10:50,760 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-07 15:10:50,760 - gpt_researcher.scraper.scraper - INFO - URL: https://www.careerindia.com/features/indian-premier-league-ipl-history-teams-format-records-049319.html
2025-05-07 15:10:50,760 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,764 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025 Auction Teams | Full Squads, Players Analysis & Team Strategy
2025-05-07 15:10:50,764 - gpt_researcher.scraper.scraper - INFO - Content length: 1579 characters
2025-05-07 15:10:50,764 - gpt_researcher.scraper.scraper - INFO - Number of images: 1
2025-05-07 15:10:50,764 - gpt_researcher.scraper.scraper - INFO - URL: https://www.crictracker.com/auction/ipl-auction/teams/
2025-05-07 15:10:50,764 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,825 - research - INFO - Scraped data size: 5
2025-05-07 15:10:50,913 - gpt_researcher.scraper.scraper - INFO - 
Title: 2025 Indian Premier League - Wikipedia
2025-05-07 15:10:50,913 - gpt_researcher.scraper.scraper - INFO - Content length: 63105 characters
2025-05-07 15:10:50,913 - gpt_researcher.scraper.scraper - INFO - Number of images: 1
2025-05-07 15:10:50,913 - gpt_researcher.scraper.scraper - INFO - URL: https://en.wikipedia.org/wiki/2025_Indian_Premier_League
2025-05-07 15:10:50,913 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:50,913 - gpt_researcher.scraper.scraper - INFO - 
Title: How the IPL Format Works? | Explained - Cricket Resolved
2025-05-07 15:10:50,913 - gpt_researcher.scraper.scraper - INFO - Content length: 5970 characters
2025-05-07 15:10:50,913 - gpt_researcher.scraper.scraper - INFO - Number of images: 7
2025-05-07 15:10:50,913 - gpt_researcher.scraper.scraper - INFO - URL: https://cricketresolved.com/how-the-ipl-format-works/
2025-05-07 15:10:50,913 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:51,248 - gpt_researcher.scraper.scraper - INFO - 
Title: Inspiring Story of the Indian Premier League (IPL) | The Rise and Impact - InspiNews
2025-05-07 15:10:51,248 - gpt_researcher.scraper.scraper - INFO - Content length: 8284 characters
2025-05-07 15:10:51,248 - gpt_researcher.scraper.scraper - INFO - Number of images: 6
2025-05-07 15:10:51,248 - gpt_researcher.scraper.scraper - INFO - URL: https://www.iuemag.com/inspi-news/iu/inspiring-story-of-the-indian-premier-league-ipl-the-rise-and-impact/
2025-05-07 15:10:51,248 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:51,254 - research - INFO - Scraped data size: 4
2025-05-07 15:10:51,341 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025 Overview: Start Date, Schedule, Venues, and More - FactoData
2025-05-07 15:10:51,342 - gpt_researcher.scraper.scraper - INFO - Content length: 3107 characters
2025-05-07 15:10:51,342 - gpt_researcher.scraper.scraper - INFO - Number of images: 1
2025-05-07 15:10:51,342 - gpt_researcher.scraper.scraper - INFO - URL: https://factodata.com/ipl-2025-overview-start-date-schedule-venues-and-more/
2025-05-07 15:10:51,342 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:51,362 - gpt_researcher.scraper.scraper - INFO - 
Title: IPL 2025 Schedule: Full List of Matches, Fixtures, Dates, Venues, and Timings- IPL
2025-05-07 15:10:51,362 - gpt_researcher.scraper.scraper - INFO - Content length: 11839 characters
2025-05-07 15:10:51,362 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-07 15:10:51,362 - gpt_researcher.scraper.scraper - INFO - URL: https://www.ipl.com/cricket/news/ipl-2025-schedule-full-list-of-matches-fixtures-dates-venues-and-timings/
2025-05-07 15:10:51,362 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-07 15:10:51,369 - research - INFO - Scraped data size: 5
2025-05-07 15:10:51,982 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:10:51,982 - research - ERROR - Error processing sub-query what is the ipl: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:10:52,123 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:10:52,124 - research - ERROR - Error processing sub-query IPL 2025 teams and player auction details: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:10:52,194 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:10:52,196 - research - ERROR - Error processing sub-query IPL cricket league history and format: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:10:52,593 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:10:52,595 - research - ERROR - Error processing sub-query Indian Premier League IPL 2025 overview: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:10:52,598 - research - INFO - Gathered context from 4 sub-queries
2025-05-07 15:10:52,602 - research - INFO - Research completed. Context size: 62
2025-05-07 15:10:53,600 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:11:15,327 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:11:15,331 - backend.server.server_utils - ERROR - Error running task: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 84, in start_streaming
    self.chat_agent = ChatAgentWithMemory(report, config_path, headers)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 27, in __init__
    self.graph = self.create_agent()
                 ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 52, in create_agent
    self.vector_store.add_texts(documents)
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/base.py", line 111, in add_texts
    return self.add_documents(docs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/in_memory.py", line 175, in add_documents
    vectors = self.embedding.embed_documents(texts)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}

2025-05-07 15:13:07,547 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:13:07,556 - research - INFO - Starting research for query: scan through my docs
2025-05-07 15:13:07,565 - research - INFO - Using local search
2025-05-07 15:13:07,580 - research - INFO - Loaded 1 documents
2025-05-07 15:13:07,580 - research - INFO - Starting web search for query: scan through my docs
2025-05-07 15:13:07,580 - research - INFO - Planning research for query: scan through my docs
2025-05-07 15:13:10,042 - research - INFO - Initial search results obtained: 10 results
2025-05-07 15:13:11,260 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:13:11,267 - research - INFO - Research outline planned: ['how to scan documents using Windows 11', 'best scanner software for multifunction printers May 2025', 'how to troubleshoot scanner issues on Windows 10 and 11']
2025-05-07 15:13:11,267 - research - INFO - Generated sub-queries: ['how to scan documents using Windows 11', 'best scanner software for multifunction printers May 2025', 'how to troubleshoot scanner issues on Windows 10 and 11']
2025-05-07 15:13:11,944 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:13:11,945 - research - ERROR - Error processing sub-query how to scan documents using Windows 11: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:13:11,954 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:13:11,954 - research - ERROR - Error processing sub-query scan through my docs: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:13:11,955 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:13:11,955 - research - ERROR - Error processing sub-query best scanner software for multifunction printers May 2025: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:13:11,982 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:13:11,983 - research - ERROR - Error processing sub-query how to troubleshoot scanner issues on Windows 10 and 11: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:13:11,983 - research - INFO - Gathered context from 4 sub-queries
2025-05-07 15:13:11,985 - research - INFO - Research completed. Context size: 2
2025-05-07 15:13:12,785 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:13:20,863 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:13:21,149 - backend.server.server_utils - ERROR - Error running task: Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 48, in run
    report = await self.gpt_researcher.write_report()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 209, in write_report
    report = await self.report_generator.write_report(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/writer.py", line 81, in write_report
    await stream_output(
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/utils.py", line 29, in stream_output
    await websocket.send_json(
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 48, in send_json
    await self.websocket.send_json(data)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 175, in send_json
    await self.send({"type": "websocket.send", "text": text})
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 85, in send
    await self._send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/_exception_handler.py", line 39, in sender
    await send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py", line 359, in asgi_send
    raise RuntimeError(msg % message_type)
RuntimeError: Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.

2025-05-07 15:13:21,150 - asyncio - ERROR - Task exception was never retrieved
future: <Task finished name='Task-4242' coro=<handle_websocket_communication.<locals>.run_long_running_task.<locals>.safe_run() done, defined at /Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py:253> exception=RuntimeError("Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.")>
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 82, in start_streaming
    report = await run_agent(task, report_type, report_source, source_urls, document_urls, tone, websocket, headers=headers, query_domains=query_domains, config_path=config_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 138, in run_agent
    report = await researcher.run()
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/report_type/basic_report/basic_report.py", line 48, in run
    report = await self.gpt_researcher.write_report()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/agent.py", line 209, in write_report
    report = await self.report_generator.write_report(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/writer.py", line 81, in write_report
    await stream_output(
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/actions/utils.py", line 29, in stream_output
    await websocket.send_json(
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 48, in send_json
    await self.websocket.send_json(data)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 175, in send_json
    await self.send({"type": "websocket.send", "text": text})
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 85, in send
    await self._send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/_exception_handler.py", line 39, in sender
    await send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py", line 359, in asgi_send
    raise RuntimeError(msg % message_type)
RuntimeError: Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 261, in safe_run
    await websocket.send_json(
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 175, in send_json
    await self.send({"type": "websocket.send", "text": text})
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/websockets.py", line 85, in send
    await self._send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/starlette/_exception_handler.py", line 39, in sender
    await send(message)
  File "/opt/homebrew/lib/python3.11/site-packages/uvicorn/protocols/websockets/websockets_impl.py", line 359, in asgi_send
    raise RuntimeError(msg % message_type)
RuntimeError: Unexpected ASGI message 'websocket.send', after sending 'websocket.close' or response already completed.
2025-05-07 15:14:22,141 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:14:22,150 - research - INFO - Starting research for query: what is my overall grade
2025-05-07 15:14:22,159 - research - INFO - Using local search
2025-05-07 15:14:22,173 - research - INFO - Loaded 1 documents
2025-05-07 15:14:22,173 - research - INFO - Starting web search for query: what is my overall grade
2025-05-07 15:14:22,173 - research - INFO - Planning research for query: what is my overall grade
2025-05-07 15:14:24,909 - research - INFO - Initial search results obtained: 10 results
2025-05-07 15:14:26,170 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:14:26,178 - research - INFO - Research outline planned: ['how to calculate overall grade using online grade calculators', 'best online tools for calculating final course grade', 'overall grade calculation with weighted components']
2025-05-07 15:14:26,179 - research - INFO - Generated sub-queries: ['how to calculate overall grade using online grade calculators', 'best online tools for calculating final course grade', 'overall grade calculation with weighted components']
2025-05-07 15:14:26,820 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:14:26,822 - research - ERROR - Error processing sub-query how to calculate overall grade using online grade calculators: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:14:26,832 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:14:26,833 - research - ERROR - Error processing sub-query best online tools for calculating final course grade: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:14:26,853 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:14:26,853 - research - ERROR - Error processing sub-query overall grade calculation with weighted components: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:14:26,868 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:14:26,869 - research - ERROR - Error processing sub-query what is my overall grade: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:14:26,870 - research - INFO - Gathered context from 4 sub-queries
2025-05-07 15:14:26,871 - research - INFO - Research completed. Context size: 2
2025-05-07 15:14:27,675 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:14:40,664 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:14:40,668 - backend.server.server_utils - ERROR - Error running task: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 84, in start_streaming
    self.chat_agent = ChatAgentWithMemory(report, config_path, headers)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 27, in __init__
    self.graph = self.create_agent()
                 ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 52, in create_agent
    self.vector_store.add_texts(documents)
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/base.py", line 111, in add_texts
    return self.add_documents(docs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/in_memory.py", line 175, in add_documents
    vectors = self.embedding.embed_documents(texts)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}

2025-05-07 15:18:35,297 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:18:35,307 - research - INFO - Starting research for query: what is my overall grade
2025-05-07 15:18:35,312 - research - INFO - Using local search
2025-05-07 15:18:35,331 - research - INFO - Loaded 1 documents
2025-05-07 15:18:35,331 - research - INFO - Starting web search for query: what is my overall grade
2025-05-07 15:18:35,331 - research - INFO - Planning research for query: what is my overall grade
2025-05-07 15:18:37,389 - research - INFO - Initial search results obtained: 10 results
2025-05-07 15:18:38,646 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:18:38,651 - research - INFO - Research outline planned: ['how to calculate overall grade using online grade calculators', 'best online tools for calculating final course grade', 'methods to determine overall grade with weighted averages']
2025-05-07 15:18:38,652 - research - INFO - Generated sub-queries: ['how to calculate overall grade using online grade calculators', 'best online tools for calculating final course grade', 'methods to determine overall grade with weighted averages']
2025-05-07 15:18:39,305 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:18:39,306 - research - ERROR - Error processing sub-query how to calculate overall grade using online grade calculators: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:18:39,315 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:18:39,315 - research - ERROR - Error processing sub-query what is my overall grade: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:18:39,320 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:18:39,321 - research - ERROR - Error processing sub-query methods to determine overall grade with weighted averages: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:18:39,342 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:18:39,343 - research - ERROR - Error processing sub-query best online tools for calculating final course grade: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:18:39,344 - research - INFO - Gathered context from 4 sub-queries
2025-05-07 15:18:39,346 - research - INFO - Research completed. Context size: 2
2025-05-07 15:18:40,273 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:18:57,602 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:18:57,605 - backend.server.server_utils - ERROR - Error running task: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 84, in start_streaming
    self.chat_agent = ChatAgentWithMemory(report, config_path, headers)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 27, in __init__
    self.graph = self.create_agent()
                 ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 52, in create_agent
    self.vector_store.add_texts(documents)
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/base.py", line 111, in add_texts
    return self.add_documents(docs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/in_memory.py", line 175, in add_documents
    vectors = self.embedding.embed_documents(texts)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}

2025-05-07 15:24:16,523 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:24:16,848 - research - INFO - Starting research for query: what are js interview questions
2025-05-07 15:24:16,850 - research - INFO - Using local search
2025-05-07 15:24:16,996 - research - INFO - Loaded 14 documents
2025-05-07 15:24:16,996 - research - INFO - Starting web search for query: what are js interview questions
2025-05-07 15:24:16,996 - research - INFO - Planning research for query: what are js interview questions
2025-05-07 15:24:19,461 - research - INFO - Initial search results obtained: 10 results
2025-05-07 15:24:20,970 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:24:20,979 - research - INFO - Research outline planned: ['JavaScript interview questions 2025 for freshers and experienced', 'Top JavaScript coding interview questions with code examples', 'Advanced JavaScript concepts for mid-level developer interviews']
2025-05-07 15:24:20,979 - research - INFO - Generated sub-queries: ['JavaScript interview questions 2025 for freshers and experienced', 'Top JavaScript coding interview questions with code examples', 'Advanced JavaScript concepts for mid-level developer interviews']
2025-05-07 15:24:21,934 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:24:21,936 - research - ERROR - Error processing sub-query Top JavaScript coding interview questions with code examples: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:24:21,938 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:24:21,953 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:24:22,001 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:24:22,018 - research - ERROR - Error processing sub-query Advanced JavaScript concepts for mid-level developer interviews: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:24:22,020 - research - ERROR - Error processing sub-query JavaScript interview questions 2025 for freshers and experienced: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:24:22,023 - research - ERROR - Error processing sub-query what are js interview questions: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:24:22,025 - research - INFO - Gathered context from 4 sub-queries
2025-05-07 15:24:22,030 - research - INFO - Research completed. Context size: 2
2025-05-07 15:24:22,989 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:24:38,135 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:24:38,151 - backend.server.server_utils - ERROR - Error running task: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 84, in start_streaming
    self.chat_agent = ChatAgentWithMemory(report, config_path, headers)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 27, in __init__
    self.graph = self.create_agent()
                 ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 52, in create_agent
    self.vector_store.add_texts(documents)
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/base.py", line 111, in add_texts
    return self.add_documents(docs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/in_memory.py", line 175, in add_documents
    vectors = self.embedding.embed_documents(texts)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}

2025-05-07 15:35:00,261 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:35:00,629 - research - INFO - Starting research for query: what is my overall grade
2025-05-07 15:35:00,632 - research - INFO - Using local search
2025-05-07 15:35:00,890 - research - INFO - Loaded 14 documents
2025-05-07 15:35:00,890 - research - INFO - Starting web search for query: what is my overall grade
2025-05-07 15:35:00,890 - research - INFO - Planning research for query: what is my overall grade
2025-05-07 15:35:03,413 - research - INFO - Initial search results obtained: 10 results
2025-05-07 15:35:05,077 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:35:05,082 - research - INFO - Research outline planned: ['how to calculate overall grade using a grade calculator', 'best online tools for determining final course grade', 'calculating weighted grades for overall academic performance']
2025-05-07 15:35:05,082 - research - INFO - Generated sub-queries: ['how to calculate overall grade using a grade calculator', 'best online tools for determining final course grade', 'calculating weighted grades for overall academic performance']
2025-05-07 15:35:06,061 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-ada/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:35:06,062 - research - ERROR - Error processing sub-query best online tools for determining final course grade: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:35:06,065 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-ada/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:35:06,066 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-ada/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:35:06,101 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-ada/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:35:06,322 - research - ERROR - Error processing sub-query calculating weighted grades for overall academic performance: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:35:06,324 - research - ERROR - Error processing sub-query how to calculate overall grade using a grade calculator: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:35:06,325 - research - ERROR - Error processing sub-query what is my overall grade: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:35:06,328 - research - INFO - Gathered context from 4 sub-queries
2025-05-07 15:35:06,330 - research - INFO - Research completed. Context size: 2
2025-05-07 15:35:07,261 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:35:19,154 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-ada/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:35:19,176 - backend.server.server_utils - ERROR - Error running task: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 84, in start_streaming
    self.chat_agent = ChatAgentWithMemory(report, config_path, headers)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 27, in __init__
    self.graph = self.create_agent()
                 ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 52, in create_agent
    self.vector_store.add_texts(documents)
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/base.py", line 111, in add_texts
    return self.add_documents(docs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/in_memory.py", line 175, in add_documents
    vectors = self.embedding.embed_documents(texts)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}

2025-05-07 15:37:43,699 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:37:43,926 - research - INFO - Starting research for query: what is my grade
2025-05-07 15:37:43,932 - research - INFO - Using local search
2025-05-07 15:37:44,035 - research - INFO - Loaded 14 documents
2025-05-07 15:37:44,035 - research - INFO - Starting web search for query: what is my grade
2025-05-07 15:37:44,035 - research - INFO - Planning research for query: what is my grade
2025-05-07 15:37:46,297 - research - INFO - Initial search results obtained: 10 results
2025-05-07 15:37:48,070 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:37:48,075 - research - INFO - Research outline planned: ['how to use a grade calculator to determine final grade', 'best online tools for calculating current and final grades', 'how to calculate grade needed on final exam to achieve desired course grade']
2025-05-07 15:37:48,075 - research - INFO - Generated sub-queries: ['how to use a grade calculator to determine final grade', 'best online tools for calculating current and final grades', 'how to calculate grade needed on final exam to achieve desired course grade']
2025-05-07 15:37:48,983 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:37:48,984 - research - ERROR - Error processing sub-query how to use a grade calculator to determine final grade: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:37:49,016 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:37:49,017 - research - ERROR - Error processing sub-query best online tools for calculating current and final grades: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:37:49,083 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:37:49,084 - research - ERROR - Error processing sub-query how to calculate grade needed on final exam to achieve desired course grade: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:37:49,100 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:37:49,101 - research - ERROR - Error processing sub-query what is my grade: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
2025-05-07 15:37:49,101 - research - INFO - Gathered context from 4 sub-queries
2025-05-07 15:37:49,103 - research - INFO - Research completed. Context size: 2
2025-05-07 15:37:49,927 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:38:17,365 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2024-05-01-preview "HTTP/1.1 404 DeploymentNotFound"
2025-05-07 15:38:17,372 - backend.server.server_utils - ERROR - Error running task: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 255, in safe_run
    await awaitable
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/server_utils.py", line 150, in handle_start_command
    report = await manager.start_streaming(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/server/websocket_manager.py", line 84, in start_streaming
    self.chat_agent = ChatAgentWithMemory(report, config_path, headers)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 27, in __init__
    self.graph = self.create_agent()
                 ^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/backend/chat/chat.py", line 52, in create_agent
    self.vector_store.add_texts(documents)
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/base.py", line 111, in add_texts
    return self.add_documents(docs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores/in_memory.py", line 175, in add_documents
    vectors = self.embedding.embed_documents(texts)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.NotFoundError: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}

2025-05-07 15:44:00,679 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:44:00,928 - research - INFO - Starting research for query: hi what is my total cgpa and sgpa
2025-05-07 15:44:00,935 - research - INFO - Using local search
2025-05-07 15:44:01,302 - research - INFO - Loaded 14 documents
2025-05-07 15:44:01,303 - research - INFO - Starting web search for query: hi what is my total cgpa and sgpa
2025-05-07 15:44:01,303 - research - INFO - Planning research for query: hi what is my total cgpa and sgpa
2025-05-07 15:44:03,729 - research - INFO - Initial search results obtained: 10 results
2025-05-07 15:44:04,937 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:44:04,944 - research - INFO - Research outline planned: ['how to calculate total cgpa from sgpa', 'difference between cgpa and sgpa calculation', 'sgpa to cgpa conversion method']
2025-05-07 15:44:04,945 - research - INFO - Generated sub-queries: ['how to calculate total cgpa from sgpa', 'difference between cgpa and sgpa calculation', 'sgpa to cgpa conversion method']
2025-05-07 15:44:06,076 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:44:06,096 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:44:06,147 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:44:06,210 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:44:06,744 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:44:07,159 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:44:07,159 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:44:07,159 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:44:07,165 - research - INFO - Content found for sub-query: 418 chars
2025-05-07 15:44:07,168 - research - INFO - Content found for sub-query: 418 chars
2025-05-07 15:44:07,170 - research - INFO - Content found for sub-query: 418 chars
2025-05-07 15:44:07,171 - research - INFO - Content found for sub-query: 418 chars
2025-05-07 15:44:07,171 - research - INFO - Gathered context from 4 sub-queries
2025-05-07 15:44:07,171 - research - INFO - Combined context size: 1675
2025-05-07 15:44:07,173 - research - INFO - Research completed. Context size: 1675
2025-05-07 15:44:08,096 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-07 15:44:17,400 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:43:39,492 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:43:39,735 - research - INFO - Starting research for query: How do I troubleshoot any error in my machine. tell me by reading manual
2025-05-08 11:43:39,738 - research - INFO - Using local search
2025-05-08 11:43:41,532 - research - INFO - Loaded 390 documents
2025-05-08 11:43:41,532 - research - INFO - Starting web search for query: How do I troubleshoot any error in my machine. tell me by reading manual
2025-05-08 11:43:41,532 - research - INFO - Planning research for query: How do I troubleshoot any error in my machine. tell me by reading manual
2025-05-08 11:43:44,033 - research - INFO - Initial search results obtained: 10 results
2025-05-08 11:43:45,260 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:43:45,269 - research - INFO - Research outline planned: ['how to troubleshoot computer errors using a manual', 'steps to diagnose computer issues by reading the user manual', 'guide to fixing PC problems by consulting the manual']
2025-05-08 11:43:45,269 - research - INFO - Generated sub-queries: ['how to troubleshoot computer errors using a manual', 'steps to diagnose computer issues by reading the user manual', 'guide to fixing PC problems by consulting the manual']
2025-05-08 11:43:49,207 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:43:49,207 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 11:43:50,156 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:43:50,156 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 11:43:50,766 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:43:50,767 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 11:43:51,759 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:43:51,760 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 11:44:52,058 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:44:52,060 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 11:44:52,884 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:44:52,885 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 11:44:53,538 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:44:53,539 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 11:44:54,664 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:44:54,665 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 11:45:55,017 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:45:55,028 - research - ERROR - Error processing sub-query how to troubleshoot computer errors using a manual: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Embeddings_Create Operation under Azure OpenAI API version 2024-05-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1056, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1105, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1056, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1105, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Embeddings_Create Operation under Azure OpenAI API version 2024-05-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}
2025-05-08 11:45:55,483 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:45:55,484 - research - ERROR - Error processing sub-query steps to diagnose computer issues by reading the user manual: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Embeddings_Create Operation under Azure OpenAI API version 2024-05-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1056, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1105, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1056, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1105, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Embeddings_Create Operation under Azure OpenAI API version 2024-05-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}
2025-05-08 11:45:56,571 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:45:56,572 - research - ERROR - Error processing sub-query guide to fixing PC problems by consulting the manual: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Embeddings_Create Operation under Azure OpenAI API version 2024-05-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1056, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1105, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1056, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1105, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Embeddings_Create Operation under Azure OpenAI API version 2024-05-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}
2025-05-08 11:45:57,462 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:45:57,463 - research - ERROR - Error processing sub-query How do I troubleshoot any error in my machine. tell me by reading manual: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Embeddings_Create Operation under Azure OpenAI API version 2024-05-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}
Traceback (most recent call last):
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/researcher.py", line 289, in _process_sub_query
    content = await self.researcher.context_manager.get_similar_content_by_query(sub_query, scraped_data)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/skills/context_manager.py", line 28, in get_similar_content_by_query
    return await context_compressor.async_get_context(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shtlpmac078/Documents/work/gpt-researcher/gpt_researcher/context/compression.py", line 76, in async_get_context
    relevant_docs = await asyncio.to_thread(compressed_docs.invoke, query)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_core/retrievers.py", line 259, in invoke
    result = self._get_relevant_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/contextual_compression.py", line 48, in _get_relevant_documents
    compressed_docs = self.base_compressor.compress_documents(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/base.py", line 39, in compress_documents
    documents = _transformer.compress_documents(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain/retrievers/document_compressors/embeddings_filter.py", line 73, in compress_documents
    embedded_documents = _get_embeddings_from_stateful_docs(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_community/document_transformers/embeddings_redundant_filter.py", line 71, in _get_embeddings_from_stateful_docs
    embedded_documents = embeddings.embed_documents(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 588, in embed_documents
    return self._get_len_safe_embeddings(texts, engine=engine)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py", line 483, in _get_len_safe_embeddings
    response = self.client.create(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/resources/embeddings.py", line 128, in create
    return self._post(
           ^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1290, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 967, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1056, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1105, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1056, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1105, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py", line 1071, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Embeddings_Create Operation under Azure OpenAI API version 2024-05-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}
2025-05-08 11:45:57,476 - research - INFO - Gathered context from 4 sub-queries
2025-05-08 11:45:57,483 - research - INFO - Research completed. Context size: 2
2025-05-08 11:45:58,369 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:46:14,416 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:49:58,905 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:49:59,188 - research - INFO - Starting research for query: tell me the specifications for endlock cylinder
2025-05-08 11:49:59,200 - research - INFO - Using local search
2025-05-08 11:49:59,785 - research - INFO - Loaded 77 documents
2025-05-08 11:49:59,785 - research - INFO - Starting web search for query: tell me the specifications for endlock cylinder
2025-05-08 11:49:59,785 - research - INFO - Planning research for query: tell me the specifications for endlock cylinder
2025-05-08 11:50:02,118 - research - INFO - Initial search results obtained: 10 results
2025-05-08 11:50:03,350 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:50:03,352 - research - INFO - Research outline planned: ['Endlock cylinder specifications Series 63 PDF', 'Endlock cylinder locking mechanism details', 'Endlock cylinder pneumatic features and sizes']
2025-05-08 11:50:03,352 - research - INFO - Generated sub-queries: ['Endlock cylinder specifications Series 63 PDF', 'Endlock cylinder locking mechanism details', 'Endlock cylinder pneumatic features and sizes']
2025-05-08 11:50:05,288 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:50:05,288 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 11:50:05,380 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:50:05,381 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 11:50:05,997 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:50:06,191 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:50:09,549 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:50:09,576 - research - INFO - Content found for sub-query: 9266 chars
2025-05-08 11:50:09,719 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:50:09,727 - research - INFO - Content found for sub-query: 9352 chars
2025-05-08 11:51:07,670 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:51:07,797 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:51:11,067 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:51:11,088 - research - INFO - Content found for sub-query: 9271 chars
2025-05-08 11:51:11,118 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:51:11,130 - research - INFO - Content found for sub-query: 9337 chars
2025-05-08 11:51:11,130 - research - INFO - Gathered context from 4 sub-queries
2025-05-08 11:51:11,130 - research - INFO - Combined context size: 37229
2025-05-08 11:51:11,133 - research - INFO - Research completed. Context size: 37229
2025-05-08 11:51:12,693 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:51:27,881 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:54:13,514 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:54:13,527 - research - INFO - Starting research for query: what will I need to check if my endlock cylinder is not working
2025-05-08 11:54:13,535 - research - INFO - Using local search
2025-05-08 11:54:14,024 - research - INFO - Loaded 77 documents
2025-05-08 11:54:14,024 - research - INFO - Starting web search for query: what will I need to check if my endlock cylinder is not working
2025-05-08 11:54:14,024 - research - INFO - Planning research for query: what will I need to check if my endlock cylinder is not working
2025-05-08 11:54:16,792 - research - INFO - Initial search results obtained: 10 results
2025-05-08 11:54:18,527 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:54:18,533 - research - INFO - Research outline planned: ['endlock cylinder troubleshooting guide', 'how to fix endlock cylinder locking issues', 'endlock cylinder maintenance and repair tips']
2025-05-08 11:54:18,533 - research - INFO - Generated sub-queries: ['endlock cylinder troubleshooting guide', 'how to fix endlock cylinder locking issues', 'endlock cylinder maintenance and repair tips']
2025-05-08 11:54:20,405 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:54:20,405 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 11:54:20,494 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 11:54:20,495 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 11:54:21,201 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:54:21,256 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:54:24,826 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:54:24,842 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:54:24,861 - research - INFO - Content found for sub-query: 9287 chars
2025-05-08 11:54:24,861 - research - INFO - Content found for sub-query: 9266 chars
2025-05-08 11:55:22,536 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:55:22,902 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:55:26,146 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:55:26,163 - research - INFO - Content found for sub-query: 9260 chars
2025-05-08 11:55:26,482 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:55:26,492 - research - INFO - Content found for sub-query: 10022 chars
2025-05-08 11:55:26,492 - research - INFO - Gathered context from 4 sub-queries
2025-05-08 11:55:26,493 - research - INFO - Combined context size: 37838
2025-05-08 11:55:26,494 - research - INFO - Research completed. Context size: 37838
2025-05-08 11:55:28,063 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 11:55:40,286 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:15:20,216 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:15:20,224 - research - INFO - Starting research for query: what will I need to check if my endlock cylinder is not working
2025-05-08 12:15:20,680 - research - INFO - Starting web search for query: what will I need to check if my endlock cylinder is not working
2025-05-08 12:15:20,680 - research - INFO - Planning research for query: what will I need to check if my endlock cylinder is not working
2025-05-08 12:15:23,236 - research - INFO - Initial search results obtained: 10 results
2025-05-08 12:15:25,078 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:15:25,085 - research - INFO - Research outline planned: ['how to troubleshoot endlock cylinder not working', 'endlock cylinder maintenance and repair guide', 'common issues with endlock cylinders and solutions']
2025-05-08 12:15:25,085 - research - INFO - Generated sub-queries: ['how to troubleshoot endlock cylinder not working', 'endlock cylinder maintenance and repair guide', 'common issues with endlock cylinders and solutions']
2025-05-08 12:15:26,858 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 12:15:26,859 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 12:15:27,009 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 12:15:27,010 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 12:15:27,742 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:15:27,743 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:15:31,209 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:15:31,228 - research - INFO - Content found for sub-query: 9253 chars
2025-05-08 12:15:31,239 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:15:31,256 - research - INFO - Content found for sub-query: 10035 chars
2025-05-08 12:16:29,258 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:16:29,298 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:16:32,653 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:16:32,665 - research - INFO - Content found for sub-query: 10022 chars
2025-05-08 12:16:32,865 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:16:32,884 - research - INFO - Content found for sub-query: 10038 chars
2025-05-08 12:16:32,884 - research - INFO - Gathered context from 4 sub-queries
2025-05-08 12:16:32,884 - research - INFO - Combined context size: 39351
2025-05-08 12:16:32,885 - research - INFO - Starting web search for query: what will I need to check if my endlock cylinder is not working
2025-05-08 12:16:32,885 - research - INFO - Planning research for query: what will I need to check if my endlock cylinder is not working
2025-05-08 12:16:34,520 - research - INFO - Initial search results obtained: 10 results
2025-05-08 12:16:35,736 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:16:35,743 - research - INFO - Research outline planned: ['how to troubleshoot endlock cylinder not locking', 'common issues with endlock cylinders and solutions', 'maintenance tips for pneumatic endlock cylinders']
2025-05-08 12:16:35,743 - research - INFO - Generated sub-queries: ['how to troubleshoot endlock cylinder not locking', 'common issues with endlock cylinders and solutions', 'maintenance tips for pneumatic endlock cylinders']
2025-05-08 12:16:37,921 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:37,923 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:37,924 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:37,925 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:37,929 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:38,132 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:38,133 - gpt_researcher.scraper.scraper - INFO - 
=== Using PyMuPDFScraper ===
2025-05-08 12:16:38,134 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:38,135 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:38,228 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:38,236 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:38,238 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:38,239 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:38,498 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:38,498 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:38,653 - gpt_researcher.scraper.scraper - INFO - 
Title: Cylinder with end lock - YouTube
2025-05-08 12:16:38,653 - gpt_researcher.scraper.scraper - INFO - Content length: 178 characters
2025-05-08 12:16:38,653 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-08 12:16:38,653 - gpt_researcher.scraper.scraper - INFO - URL: https://www.youtube.com/watch?v=w1FSRjSPrfI
2025-05-08 12:16:38,653 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:38,653 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:38,774 - gpt_researcher.scraper.scraper - INFO - 
Title: Pneumatic Cylinder Repair & Maintenance Guide  Cylinders, Inc.
2025-05-08 12:16:38,774 - gpt_researcher.scraper.scraper - INFO - Content length: 10411 characters
2025-05-08 12:16:38,774 - gpt_researcher.scraper.scraper - INFO - Number of images: 7
2025-05-08 12:16:38,774 - gpt_researcher.scraper.scraper - INFO - URL: https://cylindersinc.com/blog/pneumatic-cylinders-repair-and-maintenance-guide
2025-05-08 12:16:38,774 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:38,774 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-08 12:16:38,781 - gpt_researcher.scraper.scraper - INFO - 
Title: SMC FAQ: How does the locking mechanism of end lock cylinders work? - YouTube
2025-05-08 12:16:38,781 - gpt_researcher.scraper.scraper - INFO - Content length: 223 characters
2025-05-08 12:16:38,781 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-08 12:16:38,781 - gpt_researcher.scraper.scraper - INFO - URL: https://www.youtube.com/watch?v=S_1G5C9AqM4
2025-05-08 12:16:38,781 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:38,812 - gpt_researcher.scraper.scraper - INFO - 
Title: 9 Most Common Causes of Hydraulic Cylinder Failure | Cylinders, Inc.
2025-05-08 12:16:38,812 - gpt_researcher.scraper.scraper - INFO - Content length: 8191 characters
2025-05-08 12:16:38,812 - gpt_researcher.scraper.scraper - INFO - Number of images: 7
2025-05-08 12:16:38,812 - gpt_researcher.scraper.scraper - INFO - URL: https://cylindersinc.com/blog/9-most-common-causes-of-hydraulic-cylinder-failure
2025-05-08 12:16:38,812 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:39,211 - gpt_researcher.scraper.scraper - INFO - 
Title: How to Lubricate a Pneumatic Cylinder - Maintenance Tips - Rowse Pneumatics
2025-05-08 12:16:39,211 - gpt_researcher.scraper.scraper - INFO - Content length: 7464 characters
2025-05-08 12:16:39,211 - gpt_researcher.scraper.scraper - INFO - Number of images: 5
2025-05-08 12:16:39,211 - gpt_researcher.scraper.scraper - INFO - URL: https://www.rowse-pneumatics.co.uk/blog/post/how-to-lubricate-a-pneumatic-cylinder
2025-05-08 12:16:39,211 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:39,264 - gpt_researcher.scraper.scraper - INFO - 
Title: Unlocking The Secrets: A Guide To Repairing Cylindrical Door Locks | ShunShelter
2025-05-08 12:16:39,264 - gpt_researcher.scraper.scraper - INFO - Content length: 14066 characters
2025-05-08 12:16:39,264 - gpt_researcher.scraper.scraper - INFO - Number of images: 6
2025-05-08 12:16:39,264 - gpt_researcher.scraper.scraper - INFO - URL: https://shunshelter.com/article/how-to-repair-cylindrical-door-lock
2025-05-08 12:16:39,264 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:39,409 - gpt_researcher.scraper.scraper - INFO - 
Title: News
2025-05-08 12:16:39,409 - gpt_researcher.scraper.scraper - INFO - Content length: 1763 characters
2025-05-08 12:16:39,409 - gpt_researcher.scraper.scraper - INFO - Number of images: 8
2025-05-08 12:16:39,410 - gpt_researcher.scraper.scraper - INFO - URL: https://www.smctraining.com/en/newpage/newsdetail/1325
2025-05-08 12:16:39,410 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:39,501 - gpt_researcher.scraper.scraper - INFO - 
Title: Example pneumatic maintenance schedule - weekly, monthly, annual
2025-05-08 12:16:39,501 - gpt_researcher.scraper.scraper - INFO - Content length: 3703 characters
2025-05-08 12:16:39,502 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-08 12:16:39,502 - gpt_researcher.scraper.scraper - INFO - URL: https://www.valmet.com/insights/articles/up-and-running/reliability/RTPneuSched/
2025-05-08 12:16:39,502 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:39,925 - gpt_researcher.scraper.scraper - INFO - 
Title: Pneumatic Cylinder Maintenance Guide | Tameson.com
2025-05-08 12:16:39,925 - gpt_researcher.scraper.scraper - INFO - Content length: 10684 characters
2025-05-08 12:16:39,925 - gpt_researcher.scraper.scraper - INFO - Number of images: 5
2025-05-08 12:16:39,925 - gpt_researcher.scraper.scraper - INFO - URL: https://tameson.com/pages/pneumatic-cylinder-maintenance
2025-05-08 12:16:39,925 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:40,004 - gpt_researcher.scraper.scraper - INFO - 
Title: Understanding Cylinder Locks: Common Concerns and Solutions - danddhardware
2025-05-08 12:16:40,004 - gpt_researcher.scraper.scraper - INFO - Content length: 10248 characters
2025-05-08 12:16:40,004 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-08 12:16:40,004 - gpt_researcher.scraper.scraper - INFO - URL: https://www.danddhardware.com/cylinder-locks-common-concerns-and-solutions.html
2025-05-08 12:16:40,004 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:40,066 - gpt_researcher.scraper.scraper - INFO - 
Title: How to Maintain a Pneumatic Cylinder - Comprehensive Maintenance Guide - Rowse Pneumatics
2025-05-08 12:16:40,066 - gpt_researcher.scraper.scraper - INFO - Content length: 7141 characters
2025-05-08 12:16:40,066 - gpt_researcher.scraper.scraper - INFO - Number of images: 5
2025-05-08 12:16:40,066 - gpt_researcher.scraper.scraper - INFO - URL: https://www.rowse-pneumatics.co.uk/blog/post/how-to-maintain-a-pneumatic-cylinder
2025-05-08 12:16:40,066 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:40,098 - research - INFO - Scraped data size: 4
2025-05-08 12:16:40,205 - gpt_researcher.scraper.scraper - INFO - 
Title: Detailed Winkhaus Lock Problems and Troubleshooting Guide
2025-05-08 12:16:40,205 - gpt_researcher.scraper.scraper - INFO - Content length: 18029 characters
2025-05-08 12:16:40,205 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-08 12:16:40,205 - gpt_researcher.scraper.scraper - INFO - URL: https://www.acslocks.com/winkhaus-lock-problems/
2025-05-08 12:16:40,205 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:40,249 - gpt_researcher.scraper.scraper - INFO - 
Title: 5 Door Lock Problems That Should Not Be Ignored
2025-05-08 12:16:40,249 - gpt_researcher.scraper.scraper - INFO - Content length: 19063 characters
2025-05-08 12:16:40,249 - gpt_researcher.scraper.scraper - INFO - Number of images: 5
2025-05-08 12:16:40,249 - gpt_researcher.scraper.scraper - INFO - URL: https://unitedlocksmith.net/blog/5-door-lock-problems-that-should-not-be-ignored
2025-05-08 12:16:40,249 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:40,274 - research - INFO - Scraped data size: 4
2025-05-08 12:16:40,556 - gpt_researcher.scraper.scraper - INFO - 
Title: Fix Cylinder Lock Common Issues & Solutions With Checklist
2025-05-08 12:16:40,556 - gpt_researcher.scraper.scraper - INFO - Content length: 4099 characters
2025-05-08 12:16:40,556 - gpt_researcher.scraper.scraper - INFO - Number of images: 9
2025-05-08 12:16:40,556 - gpt_researcher.scraper.scraper - INFO - URL: https://southindiaagencies.com/blog/how-to-maintain-and-repair-a-cylinder-lock-a-checklist-of-common-problems-and-solutions/
2025-05-08 12:16:40,556 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:41,070 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:16:41,123 - gpt_researcher.scraper.scraper - INFO - 
Title: Fix Common Lock Problems | 3 Guys Locksmith
2025-05-08 12:16:41,123 - gpt_researcher.scraper.scraper - INFO - Content length: 12406 characters
2025-05-08 12:16:41,123 - gpt_researcher.scraper.scraper - INFO - Number of images: 4
2025-05-08 12:16:41,123 - gpt_researcher.scraper.scraper - INFO - URL: https://3guyslocksmiths.com/blog/top-10-common-lock-problems-and-how-to-fix-them/
2025-05-08 12:16:41,123 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-08 12:16:41,501 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:16:42,032 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:16:42,037 - research - INFO - Content found for sub-query: 10344 chars
2025-05-08 12:16:42,221 - gpt_researcher.scraper.scraper - WARNING - Content too short or empty for https://www.smcpneumatics.com/Troubleshooting-Your-Pneumatic-System-Issues_b_58.html
2025-05-08 12:16:42,258 - research - INFO - Scraped data size: 4
2025-05-08 12:16:42,449 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 12:16:42,452 - openai._base_client - INFO - Retrying request to /embeddings in 46.000000 seconds
2025-05-08 12:16:43,004 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:16:43,012 - research - INFO - Content found for sub-query: 10512 chars
2025-05-08 12:16:43,215 - gpt_researcher.scraper.scraper - ERROR - Error processing https://www.smcpneumatics.com/pdfs/smc/70ACB.pdf: cannot unpack non-iterable NoneType object
2025-05-08 12:16:43,251 - research - INFO - Scraped data size: 3
2025-05-08 12:16:43,613 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 12:16:43,614 - openai._base_client - INFO - Retrying request to /embeddings in 45.000000 seconds
2025-05-08 12:17:29,517 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:17:29,824 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:17:30,184 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:17:30,190 - research - INFO - Content found for sub-query: 9436 chars
2025-05-08 12:17:30,772 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:17:30,778 - research - INFO - Content found for sub-query: 10976 chars
2025-05-08 12:17:30,779 - research - INFO - Gathered context from 4 sub-queries
2025-05-08 12:17:30,779 - research - INFO - Combined context size: 41271
2025-05-08 12:17:30,972 - research - INFO - Research completed. Context size: 80680
2025-05-08 12:17:35,066 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:17:37,337 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:17:45,739 - research - INFO - Starting research for query: Common Issues with Endlock Cylinders
2025-05-08 12:17:46,148 - research - INFO - Starting web search for query: Common Issues with Endlock Cylinders
2025-05-08 12:17:46,148 - research - INFO - Planning research for query: Common Issues with Endlock Cylinders
2025-05-08 12:17:48,822 - research - INFO - Initial search results obtained: 10 results
2025-05-08 12:17:50,702 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:17:50,708 - research - INFO - Research outline planned: ['Common issues with endlock cylinders and troubleshooting tips', 'How to diagnose and fix problems with hydraulic endlock cylinders', 'Endlock cylinder not working: causes and solutions']
2025-05-08 12:17:50,708 - research - INFO - Generated sub-queries: ['Common issues with endlock cylinders and troubleshooting tips', 'How to diagnose and fix problems with hydraulic endlock cylinders', 'Endlock cylinder not working: causes and solutions']
2025-05-08 12:17:52,454 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 429 Too Many Requests"
2025-05-08 12:17:52,455 - openai._base_client - INFO - Retrying request to /embeddings in 60.000000 seconds
2025-05-08 12:17:53,222 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:17:53,433 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:17:56,646 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:17:56,663 - research - INFO - Content found for sub-query: 9269 chars
2025-05-08 12:17:57,002 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:17:57,019 - research - INFO - Content found for sub-query: 10017 chars
2025-05-08 12:18:54,926 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:18:58,797 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-08 12:18:58,817 - research - INFO - Content found for sub-query: 9260 chars
2025-05-08 12:18:58,817 - research - INFO - Gathered context from 3 sub-queries
2025-05-08 12:18:58,817 - research - INFO - Combined context size: 28548
2025-05-08 12:18:58,818 - research - INFO - Starting web search for query: Common Issues with Endlock Cylinders
2025-05-08 12:18:58,818 - research - INFO - Planning research for query: Common Issues with Endlock Cylinders
2025-05-08 12:19:01,284 - research - INFO - Initial search results obtained: 10 results
2025-05-08 12:19:03,108 - backend.server.server_utils - INFO - Task cancelled.
2025-05-14 11:58:22,339 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-14 11:58:27,457 - research - INFO - Starting research for query: How do I troubleshoot any error in my machine. tell me by reading manual
2025-05-14 11:58:27,460 - research - INFO - Using web search
2025-05-14 11:58:27,460 - research - INFO - Starting web search for query: How do I troubleshoot any error in my machine. tell me by reading manual
2025-05-14 11:58:27,460 - research - INFO - Planning research for query: How do I troubleshoot any error in my machine. tell me by reading manual
2025-05-14 11:58:30,556 - research - INFO - Initial search results obtained: 10 results
2025-05-14 11:58:33,101 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-14 11:58:33,104 - research - INFO - Research outline planned: ['how to diagnose computer problems using a manual', 'troubleshooting computer errors with device manager and manual', 'step-by-step guide to using Windows troubleshooters and manual for error fixing']
2025-05-14 11:58:33,104 - research - INFO - Generated sub-queries: ['how to diagnose computer problems using a manual', 'troubleshooting computer errors with device manager and manual', 'step-by-step guide to using Windows troubleshooters and manual for error fixing']
2025-05-14 11:58:36,272 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,272 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,273 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,275 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,277 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,480 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,480 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,481 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,483 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,484 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,556 - gpt_researcher.scraper.scraper - INFO - 
Title: Error codes in Device Manager in Windows - Microsoft Support
2025-05-14 11:58:36,557 - gpt_researcher.scraper.scraper - INFO - Content length: 30782 characters
2025-05-14 11:58:36,557 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-14 11:58:36,557 - gpt_researcher.scraper.scraper - INFO - URL: https://support.microsoft.com/en-us/topic/error-codes-in-device-manager-in-windows-524e9e89-4dee-8883-0afa-6bca0456324e
2025-05-14 11:58:36,557 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:36,575 - gpt_researcher.scraper.scraper - INFO - 
Title: How to check and fix hardware issues with Device Manager error codes on Windows 10 | Windows Central
2025-05-14 11:58:36,575 - gpt_researcher.scraper.scraper - INFO - Content length: 21573 characters
2025-05-14 11:58:36,575 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-14 11:58:36,575 - gpt_researcher.scraper.scraper - INFO - URL: https://www.windowscentral.com/how-check-and-fix-device-manager-error-codes-windows-10
2025-05-14 11:58:36,575 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:36,685 - gpt_researcher.scraper.scraper - INFO - 
Title: Windows troubleshooters - Microsoft Support
2025-05-14 11:58:36,685 - gpt_researcher.scraper.scraper - INFO - Content length: 5332 characters
2025-05-14 11:58:36,685 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-14 11:58:36,685 - gpt_researcher.scraper.scraper - INFO - URL: https://support.microsoft.com/en-us/windows/windows-troubleshooters-1c8cf7ce-0388-4ed3-985d-a305432ae702
2025-05-14 11:58:36,685 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:36,883 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,884 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,884 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,885 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,887 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,967 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:36,968 - gpt_researcher.scraper.scraper - INFO - 
=== Using BeautifulSoupScraper ===
2025-05-14 11:58:37,243 - gpt_researcher.scraper.scraper - INFO - 
Title: Windows 11 Troubleshooting Guide - The Success Manual
2025-05-14 11:58:37,243 - gpt_researcher.scraper.scraper - INFO - Content length: 6634 characters
2025-05-14 11:58:37,243 - gpt_researcher.scraper.scraper - INFO - Number of images: 1
2025-05-14 11:58:37,243 - gpt_researcher.scraper.scraper - INFO - URL: https://www.thesuccessmanual.in/chapter/windows-11-troubleshooting-guide
2025-05-14 11:58:37,243 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:37,395 - gpt_researcher.scraper.scraper - INFO - 
Title: Step By Step Troubleshooting Computer Hardware - UMA Technology
2025-05-14 11:58:37,395 - gpt_researcher.scraper.scraper - INFO - Content length: 8312 characters
2025-05-14 11:58:37,395 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-14 11:58:37,395 - gpt_researcher.scraper.scraper - INFO - URL: https://umatechnology.org/step-by-step-troubleshooting-computer-hardware/
2025-05-14 11:58:37,395 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:37,431 - gpt_researcher.scraper.scraper - INFO - 
Title: How to Troubleshoot a Computer: Expert Tricks to Fix Any PC
2025-05-14 11:58:37,431 - gpt_researcher.scraper.scraper - INFO - Content length: 34920 characters
2025-05-14 11:58:37,431 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-14 11:58:37,431 - gpt_researcher.scraper.scraper - INFO - URL: https://www.wikihow.com/Troubleshoot-a-Computer
2025-05-14 11:58:37,431 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:37,456 - gpt_researcher.scraper.scraper - INFO - 
Title: How to Diagnose a Computer Problem: 10 Steps (with Pictures)
2025-05-14 11:58:37,457 - gpt_researcher.scraper.scraper - INFO - Content length: 15293 characters
2025-05-14 11:58:37,457 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-14 11:58:37,457 - gpt_researcher.scraper.scraper - INFO - URL: https://www.wikihow.com/Diagnose-a-Computer-Problem
2025-05-14 11:58:37,457 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:37,600 - gpt_researcher.scraper.scraper - INFO - 
Title: Basic Computer Troubleshooting Guide - The Success Manual
2025-05-14 11:58:37,600 - gpt_researcher.scraper.scraper - INFO - Content length: 5725 characters
2025-05-14 11:58:37,600 - gpt_researcher.scraper.scraper - INFO - Number of images: 1
2025-05-14 11:58:37,600 - gpt_researcher.scraper.scraper - INFO - URL: https://www.thesuccessmanual.in/chapter/basic-computer-troubleshooting-guide
2025-05-14 11:58:37,600 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:37,611 - gpt_researcher.scraper.scraper - INFO - 
Title: How to Repair Windows 11: A Step-by-Step Guide to Troubleshooting Issues - Solve Your Tech
2025-05-14 11:58:37,611 - gpt_researcher.scraper.scraper - INFO - Content length: 6387 characters
2025-05-14 11:58:37,611 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-14 11:58:37,611 - gpt_researcher.scraper.scraper - INFO - URL: https://www.solveyourtech.com/how-to-repair-windows-11-a-step-by-step-guide-to-troubleshooting-issues/
2025-05-14 11:58:37,611 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:37,622 - gpt_researcher.scraper.scraper - INFO - 
Title: How to Run Troubleshooter in Windows 11: A Step-by-Step Guide - Solve Your Tech
2025-05-14 11:58:37,622 - gpt_researcher.scraper.scraper - INFO - Content length: 8060 characters
2025-05-14 11:58:37,622 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-14 11:58:37,622 - gpt_researcher.scraper.scraper - INFO - URL: https://www.solveyourtech.com/how-to-run-troubleshooter-in-windows-11-a-step-by-step-guide/
2025-05-14 11:58:37,622 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:37,833 - gpt_researcher.scraper.scraper - INFO - 
Title: How to Troubleshoot Windows 11: A Step-by-Step Guide for Beginners - Support Your Tech
2025-05-14 11:58:37,833 - gpt_researcher.scraper.scraper - INFO - Content length: 7101 characters
2025-05-14 11:58:37,833 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-14 11:58:37,833 - gpt_researcher.scraper.scraper - INFO - URL: https://www.supportyourtech.com/tech/how-to-troubleshoot-windows-11-a-step-by-step-guide-for-beginners/
2025-05-14 11:58:37,833 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:37,866 - research - INFO - Scraped data size: 5
2025-05-14 11:58:40,989 - gpt_researcher.scraper.scraper - INFO - 
Title: Computer Basics: Basic Troubleshooting Techniques
2025-05-14 11:58:40,989 - gpt_researcher.scraper.scraper - INFO - Content length: 10100 characters
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - Number of images: 10
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - URL: https://edu.gcfglobal.org/en/computerbasics/basic-troubleshooting-techniques/1/
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - 
Title: How to Use the Windows Device Manager for Troubleshooting - UMA Technology
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - Content length: 4904 characters
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - Number of images: 0
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - URL: https://umatechnology.org/how-to-use-the-windows-device-manager-for-troubleshooting/
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - 
Title: How to Use the Windows Device Manager for Troubleshooting
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - Content length: 6642 characters
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - Number of images: 8
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - URL: https://www.howtogeek.com/167094/how-to-use-the-windows-device-manager-for-troubleshooting/
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - 
Title: Step-by-Step Guide to Diagnosing Computer Hardware Issues
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - Content length: 14472 characters
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - Number of images: 8
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - URL: https://computermoz.org/step-by-step-guide-to-diagnosing-computer-hardware-issues/
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - 
Title: How to Find Out Why Your Windows PC Crashed or Froze
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - Content length: 6045 characters
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - Number of images: 6
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - URL: https://www.howtogeek.com/222730/how-to-find-out-why-your-windows-pc-crashed-or-froze/
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - 
Title: List of Device Manager Error Codes on Windows 11/10 with solutions
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - Content length: 29128 characters
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - Number of images: 1
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - URL: https://www.thewindowsclub.com/fix-device-manager-error-codes-on-windows-10
2025-05-14 11:58:40,990 - gpt_researcher.scraper.scraper - INFO - ==================================================
2025-05-14 11:58:41,021 - research - INFO - Scraped data size: 5
2025-05-14 11:58:41,065 - research - INFO - Scraped data size: 2
2025-05-14 11:58:41,101 - research - INFO - Scraped data size: 5
2025-05-14 11:58:42,088 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-14 11:58:42,324 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-14 11:58:42,343 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-14 11:58:42,725 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-14 11:58:42,890 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-14 11:58:42,922 - research - INFO - Content found for sub-query: 10175 chars
2025-05-14 11:58:43,338 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-14 11:58:43,344 - research - INFO - Content found for sub-query: 10966 chars
2025-05-14 11:58:44,114 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-14 11:58:44,125 - research - INFO - Content found for sub-query: 10622 chars
2025-05-14 11:58:44,738 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-14 11:58:44,750 - research - INFO - Content found for sub-query: 11115 chars
2025-05-14 11:58:44,751 - research - INFO - Gathered context from 4 sub-queries
2025-05-14 11:58:44,751 - research - INFO - Combined context size: 42881
2025-05-14 11:58:44,754 - research - INFO - Research completed. Context size: 42881
2025-05-14 11:58:46,321 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/gpt4o/chat/completions?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
2025-05-14 11:59:02,956 - httpx - INFO - HTTP Request: POST https://intern-training.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview "HTTP/1.1 200 OK"
